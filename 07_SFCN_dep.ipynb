{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:06.319909Z",
     "start_time": "2024-07-11T20:06:05.537605Z"
    }
   },
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import tifffile as tiff\n",
    "\n",
    "macaw_path = Path(os.getcwd())\n",
    "sys.path.append(str(macaw_path) +'/')\n",
    "\n",
    "ncomps = 50\n",
    "model_comps = 500\n",
    "dr_method = 'PCA'\n",
    "\n",
    "exp_name=\"far_bias\"\n",
    "\n",
    "test_path = train_path = macaw_path/exp_name/f'test_hc_data_PCA_{model_comps}.pkl'\n",
    "model_base_path = macaw_path/'models'/exp_name/f'{dr_method}_{model_comps}'/f'{ncomps}'"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:06.588123Z",
     "start_time": "2024-07-11T20:06:06.320844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open(test_path, 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "disease = test['disease']\n",
    "bias = test['bias']\n",
    "test_imgs = test['imgs']\n",
    "\n",
    "encoded_data = test['encoded_data']\n",
    "pca = test['pca']\n",
    "\n",
    "img_names = test['img_names']"
   ],
   "id": "c0e8522f070024f6",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:06.591691Z",
     "start_time": "2024-07-11T20:06:06.588867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(model_base_path/'hyperparameters.pkl', 'rb') as f:\n",
    "    hp = pickle.load(f)\n",
    "    \n",
    "ncomps= hp['ncomps']\n",
    "nevecs= hp['nevecs']\n",
    "nbasecomps= hp['nbasecomps']\n",
    "ncauses= hp['ncauses']\n",
    "crop_size= hp['crop_size']"
   ],
   "id": "ffb6c3fe15b1243c",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:07.313450Z",
     "start_time": "2024-07-11T20:06:06.592958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def recons(age,bmi,latents, latent_offset=0):\n",
    "    \n",
    "    # bmi = scaler_b.inverse_transform(bmi)\n",
    "    # print(age)\n",
    "    latent_enc = np.zeros((latents.shape[0],ncomps))\n",
    "    latent_enc[:,latent_offset:latent_offset+latents.shape[1]] = latents    \n",
    "    # latent_enc = scaler_i.inverse_transform(latent_enc)\n",
    "    imgs = pca.inverse_transform(latent_enc)\n",
    "    return age,bmi,imgs"
   ],
   "id": "7016f42e95479030",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:07.328024Z",
     "start_time": "2024-07-11T20:06:07.314046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_imgs = test_imgs[:5,:]\n",
    "t = pca.transform(sample_imgs)\n",
    "X_recon = pca.inverse_transform(t)"
   ],
   "id": "302ad7c430bdfe1f",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:07.330690Z",
     "start_time": "2024-07-11T20:06:07.328654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_img(x):\n",
    "    img = (255*x/np.max(x)).reshape(crop_size,crop_size)\n",
    "    return np.clip(img,0, 255).astype('uint8')"
   ],
   "id": "8bc112239b561b94",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:07.333318Z",
     "start_time": "2024-07-11T20:06:07.331274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def make_gif(frames, save_name):    \n",
    "    frames = [Image.fromarray(f) for f in frames]\n",
    "    frame_one = frames[0]\n",
    "    return frame_one.save(save_name, format=\"GIF\", append_images=frames, save_all=True, duration=100, loop=0)"
   ],
   "id": "5c2c31c31c5d17ce",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:07.335801Z",
     "start_time": "2024-07-11T20:06:07.333837Z"
    }
   },
   "cell_type": "code",
   "source": "print(img_names[247], img_names[248])",
   "id": "3352973164f64eda",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:08.819328Z",
     "start_time": "2024-07-11T20:06:07.336290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import CenterCrop\n",
    "from utils.customTransforms import ToFloatUKBB\n",
    "from monai.transforms import Compose, ToTensor\n",
    "transforms = Compose([ToTensor(),CenterCrop(crop_size),ToFloatUKBB()])"
   ],
   "id": "f68a67e80461df3e",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:11.423776Z",
     "start_time": "2024-07-11T20:06:08.820624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "save_name = f'data/cfs'\n",
    "cf_vals = {1:0}\n",
    "image_shape = (180, 180)  # Assuming each image is 180x180\n",
    "\n",
    "# rands = np.random.randint(0, encoded_data.shape[0], nsamples)\n",
    "# d_obs = test_imgs[rands, :]\n",
    "# encoded_obs = encoded_data[rands, :]\n",
    "# \n",
    "# names = img_names[rands]\n",
    "# dis_obs = disease[rands]\n",
    "# bias_obs = bias[rands]\n",
    "residuals = test_imgs - pca.inverse_transform(encoded_data)\n",
    "\n",
    "cf = np.zeros((248, ncomps))\n",
    "for ev in range(0, ncomps - nbasecomps, nevecs - nbasecomps):\n",
    "    ed = encoded_data[:248, ev:ev + nevecs]\n",
    "    X_obs = np.hstack([disease[:248, np.newaxis], bias[:248, np.newaxis], ed])\n",
    "    try:\n",
    "        macaw = torch.load(model_base_path / f'{ev}.pt')\n",
    "        cc = macaw.counterfactual(X_obs, cf_vals)\n",
    "    except Exception as e:\n",
    "        print(e, \"Using original\")\n",
    "        cc[:, ncauses:] = X_obs[:, ncauses:].copy()\n",
    "\n",
    "    cf[:, ev:ev + nevecs] = cc[:, ncauses:]\n",
    "\n",
    "re_cf = recons(cc[:, 0], cc[:, 1], cf)\n",
    "re_cf_resd = re_cf[2] + residuals[:248]\n",
    "\n",
    "# Convert numpy arrays to SimpleITK images\n",
    "def numpy_to_sitk(img):\n",
    "    return sitk.GetImageFromArray(img.astype(np.float32))\n",
    "\n",
    "def sitk_to_numpy(img):\n",
    "    return sitk.GetArrayFromImage(img)\n",
    "\n",
    "# Perform histogram matching\n",
    "matched_images = []\n",
    "for i in range(248):\n",
    "    # Reshape the arrays to 2D images\n",
    "    source_img_2d = re_cf_resd[i].reshape(image_shape).astype(np.float32)\n",
    "    reference_img_2d = test_imgs[i].reshape(image_shape).astype(np.float32)\n",
    "    \n",
    "    source_img = numpy_to_sitk(source_img_2d)\n",
    "    reference_img = numpy_to_sitk(reference_img_2d)\n",
    "    \n",
    "    matcher = sitk.HistogramMatchingImageFilter()\n",
    "    matcher.SetNumberOfHistogramLevels(500)\n",
    "    matcher.SetNumberOfMatchPoints(50)\n",
    "    matcher.SetThresholdAtMeanIntensity(False)\n",
    "    matched_img = matcher.Execute(source_img, reference_img)\n",
    "    \n",
    "    # Convert the matched image back to a numpy array and reshape to original shape\n",
    "    matched_img_array = sitk_to_numpy(matched_img).reshape(-1)\n",
    "    matched_images.append(matched_img_array)\n",
    "\n",
    "# Convert the matched images back to a numpy array\n",
    "re_cf_resd = np.array(matched_images)\n",
    "\n",
    "# Ensuring values are still in the range [0, 1] after histogram matching\n",
    "# re_cf_resd = np.clip(re_cf_resd, 0, 1)"
   ],
   "id": "529cd30aedb525ab",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:07:18.800625Z",
     "start_time": "2024-07-11T20:07:18.754883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Function to save numpy array as TIFF image\n",
    "def save_image(array, path):\n",
    "    image = Image.fromarray((array * 255).astype(np.uint8))\n",
    "    image.save(path, format='TIFF')\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "output_dir = save_name\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Assuming re_cf_resd is already a numpy array with shape (248, 180*180)\n",
    "for i, img_array in enumerate(re_cf_resd):\n",
    "    img_2d = img_array.reshape(image_shape)  # Reshape to 2D image if necessary\n",
    "    output_path = os.path.join(output_dir, img_names[i])\n",
    "    save_image(img_2d, output_path)\n",
    "\n",
    "print(f\"Images saved in {output_dir}\")\n"
   ],
   "id": "be60d56c1de72861",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:11.479466Z",
     "start_time": "2024-07-11T20:06:11.467152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "home_dir = './'\n",
    "working_dir = home_dir + exp_name + '/'\n",
    "\n",
    "# def make_img(x):\n",
    "#     img = (255*x/np.max(x)).reshape(crop_size,crop_size)\n",
    "#     return np.clip(img,0, 255).astype('uint8')\n",
    "# \n",
    "# for img in re_cf_resd:\n",
    "#     img = make_img(img)"
   ],
   "id": "8dfe5ee1f88cea54",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:11.484026Z",
     "start_time": "2024-07-11T20:06:11.480391Z"
    }
   },
   "cell_type": "code",
   "source": "re_cf_resd.shape",
   "id": "ca1669aa78b2f268",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:11.487503Z",
     "start_time": "2024-07-11T20:06:11.484714Z"
    }
   },
   "cell_type": "code",
   "source": "re_cf_resd[0].min()",
   "id": "af52997215b8d0dc",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:11.600636Z",
     "start_time": "2024-07-11T20:06:11.488179Z"
    }
   },
   "cell_type": "code",
   "source": "plt.imshow(re_cf_resd[0].reshape(180,180))",
   "id": "285f508ffbda1c05",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:11.607269Z",
     "start_time": "2024-07-11T20:06:11.601304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from monai.transforms import EnsureChannelFirst\n",
    "import torchvision\n",
    "from monai.data import DataLoader, ImageDataset\n",
    "import pandas as pd\n",
    "df_test = pd.read_csv(os.path.join(home_dir, \"splits/test.csv\"))\n",
    "\n",
    "test_fpaths = [os.path.join(\"./no_bias/\", \"test\", filename) for filename in df_test['filename']]\n",
    "test_class_label = np.zeros(len(test_fpaths))\n",
    "\n",
    "# Define transforms for image\n",
    "transforms = Compose([torchvision.transforms.CenterCrop(180), EnsureChannelFirst(), ToFloatUKBB(), ToTensor()])\n",
    "\n",
    "# Define image dataset\n",
    "test_ds = ImageDataset(image_files=test_fpaths[:248], labels=test_class_label, transform=transforms, image_only=True, reader=\"PILReader\")\n",
    "\n",
    "# create a validation data loader\n",
    "test_loader = DataLoader(test_ds, batch_size=32, num_workers=4, pin_memory=torch.cuda.is_available())"
   ],
   "id": "599e3cb522d51ce3",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:12.196267Z",
     "start_time": "2024-07-11T20:06:11.607892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.utils import *\n",
    "from SFCN import SFCNModel\n",
    "\n",
    "model = SFCNModel().to(device)\n",
    "model.load_state_dict(torch.load(working_dir + \"best_model_\" + exp_name + \".pth\"))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "re_cf_resd= re_cf_resd.reshape(re_cf_resd.shape[0], 1, crop_size,crop_size)\n",
    "\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    #     for idx, test_data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "    #         test_images = test_data[0].to(device)\n",
    "    #         \n",
    "    #         if idx==0:\n",
    "    #             print(test_images.shape)\n",
    "    # \n",
    "    #         # print(test_data[0][0].max(), test_data[0][0].min())\n",
    "    # \n",
    "    #         # Get model's probability outputs\n",
    "    #         outputs = model(test_images)\n",
    "    #         # probs = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy()\n",
    "    #         all_preds.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    for img in re_cf_resd:\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        output = model(img)\n",
    "        all_preds.append(output)\n",
    "\n",
    "# concat predictions to test dataframe\n",
    "df_test = df_test.iloc[:248]\n",
    "df = model_eval(df_test, all_preds)\n",
    "\n",
    "#create one-hot encoded columns for TP, TN, FP, FN\n",
    "df['TP'] = df.apply(lambda row: 1 if ((row['bias_label'] == 1) & (row['preds'] ==1)) else 0, axis=1)\n",
    "df['TN'] = df.apply(lambda row: 1 if ((row['bias_label'] == 0) & (row['preds'] ==0)) else 0, axis=1)\n",
    "df['FP'] = df.apply(lambda row: 1 if ((row['bias_label'] == 0) & (row['preds'] ==1)) else 0, axis=1)\n",
    "df['FN'] = df.apply(lambda row: 1 if ((row['bias_label'] == 1) & (row['preds'] ==0)) else 0, axis=1)\n",
    "\n",
    "df.to_csv(working_dir + 'preds_' + exp_name + '.csv') #save file with predictions"
   ],
   "id": "db197766deff315a",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:12.197107Z",
     "start_time": "2024-07-11T20:06:12.197032Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "77fa63d21d7b04cc",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:06:12.197742Z",
     "start_time": "2024-07-11T20:06:12.197683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute metrics\n",
    "df_B1 = df.loc[df['ground_truth']==1]\n",
    "df_B0 = df.loc[df['ground_truth']==0]\n",
    "\n",
    "#generate file with performance metrics\n",
    "metrics = compute_metrics(df, save_dir=working_dir, label='Agg')\n",
    "metrics_B1 = compute_metrics(df_B1, save_dir=working_dir, label='B1')\n",
    "metrics_B0 = compute_metrics(df_B0, save_dir=working_dir, label='B0')\n",
    "\n",
    "metrics_df = pd.DataFrame(['Acc', 'Sens', 'Spec', 'FPR', 'AUROC'], columns=['metrics'])\n",
    "metrics_df = metrics_df.set_index('metrics')\n",
    "\n",
    "metrics_df['Aggregate'] = metrics\n",
    "metrics_df['disease_1'] = metrics_B1\n",
    "metrics_df['disease_0'] = metrics_B0\n",
    "metrics_df.to_csv(working_dir + 'metrics_' + exp_name + '.csv')\n",
    "\n",
    "plot_roc_curves(df, df_B1, df_B0, save_dir=working_dir)"
   ],
   "id": "bd1f35e82e1eaecd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cae7ef8b68658be3",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
